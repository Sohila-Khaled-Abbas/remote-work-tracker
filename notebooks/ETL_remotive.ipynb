{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2cd1b06",
   "metadata": {},
   "source": [
    "# Remote Work Tracker BI Project: ETL, DB, and Utility Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a2440b",
   "metadata": {},
   "source": [
    "This Jupyter Notebook provides a comprehensive overview and demonstration of the Extract, Transform, Load (ETL) process, database interaction, and utility functions developed for the Remote Work Tracker Business Intelligence (BI) project. These scripts are designed to process raw job data (e.g., from the Remotive.com API) and store it in a structured SQLite database, making it ready for further analysis and visualization in tools like Power BI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761eb29b",
   "metadata": {},
   "source": [
    "## Project Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa18d4ca",
   "metadata": {},
   "source": [
    "The core components covered in this notebook are:\n",
    "1.  **`db_schema_and_etl_design.md`**: Documentation outlining the database schema and ETL process.\n",
    "2.  **`db_connector.py`**: Python script for connecting to and interacting with the SQLite database.\n",
    "3.  **`etl_script.py`**: Python script implementing the Extract, Transform, Load logic.\n",
    "4.  **`utils.py`**: Python script containing general utility functions, such as logging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f948b300",
   "metadata": {},
   "source": [
    "## 1. Database Schema Design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c61ecee",
   "metadata": {},
   "source": [
    "The foundation of our BI project is a well-defined database schema. We are using a simple SQLite database with a single table, `remote_jobs`, to store the processed job data. The schema is designed to capture all relevant information from the job postings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6870fb",
   "metadata": {},
   "source": [
    "### `remote_jobs` Table Structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a215442d",
   "metadata": {},
   "source": [
    "| Column Name                   | Data Type   | Constraints       | Description                                      |\n",
    "| :---------------------------- | :---------- | :---------------- | :----------------------------------------------- |\n",
    "| `id`                          | INTEGER     | PRIMARY KEY       | Unique identifier for each job posting (from API)|\n",
    "| `job_title`                   | TEXT        | NOT NULL          | Title of the job                                 |\n",
    "| `company_name`                | TEXT        | NOT NULL          | Name of the hiring company                       |\n",
    "| `company_name`                | TEXT        | NOT NULL          | Name of the hiring company                       |\n",
    "| `publication_date`            | TEXT        | NOT NULL          | Date and time the job was published (ISO format) |\n",
    "| `job_type`                    | TEXT        |                   | Type of employment (e.g., full_time, contract)   |\n",
    "| `category`                    | TEXT        |                   | Job category (e.g., Software Development)        |\n",
    "| `candidate_required_location` | TEXT        |                   | Geographical restrictions for candidates         |\n",
    "| `salary_range`                | TEXT        |                   | Stated salary range, if available                |\n",
    "| `job_description`             | TEXT        |                   | Full description of the job                      |\n",
    "| `source_url`                  | TEXT        | UNIQUE, NOT NULL  | URL to the original job posting                  |\n",
    "| `company_logo`                | TEXT        |                   | URL to the company logo                          |\n",
    "| `job_board`                   | TEXT        | NOT NULL          | Source job board (e.g., Remotive.com)            |\n",
    "| `ingestion_timestamp`         | TIMESTAMP   | DEFAULT CURRENT_TIMESTAMP | Timestamp when the record was ingested   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acacc7f2",
   "metadata": {},
   "source": [
    "*Note: The `db_schema_and_etl_design.md` file contains a more detailed explanation of the schema and ETL process.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310579a3",
   "metadata": {},
   "source": [
    "## 2. Database Connector (`db_connector.py`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de169bc",
   "metadata": {},
   "source": [
    "The `db_connector.py` script provides a `DBConnector` class to manage interactions with the SQLite database. It handles connecting, disconnecting, creating the `remote_jobs` table, and inserting job data from a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87d4fa5",
   "metadata": {},
   "source": [
    "### Key Features:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b50c87",
   "metadata": {},
   "source": [
    "- **Connection Management**: `connect()` and `disconnect()` methods for robust database handling.\n",
    "- **Schema Initialization**: `create_table()` ensures the `remote_jobs` table exists with the defined schema.\n",
    "- **Data Insertion**: `insert_jobs(df)` efficiently inserts DataFrame records, using `INSERT OR IGNORE` to prevent duplicate entries based on the `id` column (which is the primary key from the API). This is crucial for handling daily scrapes without re-inserting old data.\n",
    "- **Data Retrieval**: `fetch_all_jobs()` allows for easy retrieval of all stored job data into a Pandas DataFrame for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305a1dce",
   "metadata": {},
   "source": [
    "### Code (`db_connector.py`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b750fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "class DBConnector:\n",
    "    def __init__(self, db_name=\"remote_jobs.db\"):\n",
    "        self.db_name = db_name\n",
    "        self.conn = None\n",
    "        self.cursor = None\n",
    "\n",
    "    def connect(self):\n",
    "        \"Establishes a connection to the SQLite database.\"\n",
    "        try:\n",
    "            self.conn = sqlite3.connect(self.db_name)\n",
    "            self.cursor = self.conn.cursor()\n",
    "            print(f\"Connected to database: {self.db_name}\")\n",
    "        except sqlite3.Error as e:\n",
    "            print(f\"Error connecting to database: {e}\")\n",
    "\n",
    "    def disconnect(self):\n",
    "        \"Closes the connection to the SQLite database.\"\n",
    "        if self.conn:\n",
    "            self.conn.close()\n",
    "            print(\"Disconnected from database.\")\n",
    "\n",
    "    def create_table(self):\n",
    "        \"Creates the jobs table if it doesn't exist.\"\n",
    "        create_table_query = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS remote_jobs (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            job_title TEXT,\n",
    "            company TEXT,\n",
    "            location TEXT,\n",
    "            date_posted TEXT,\n",
    "            job_description TEXT,\n",
    "            url TEXT UNIQUE,\n",
    "            date_scraped TEXT\n",
    "        );\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.cursor.execute(create_table_query)\n",
    "            self.conn.commit()\n",
    "            print(\"Jobs table created or already exists.\")\n",
    "        except sqlite3.Error as e:\n",
    "            print(f\"Error creating table: {e}\")\n",
    "                    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
