{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remote Work Job Scraper: Remotive.com API\n",
    "\n",
    "This Jupyter Notebook demonstrates how to fetch real remote job postings using the [Remotive.com Public API](https://remotive.com/remote-jobs/api). Utilizing an API is often the most robust and polite method for collecting data from websites, as it bypasses the complexities of HTML parsing and anti-scraping measures associated with traditional web scraping.\n",
    "\n",
    "## 1. Setup and Configuration\n",
    "\n",
    "We begin by importing the necessary Python libraries: `requests` for making HTTP requests to the API, `pandas` for data manipulation, and `time` for potential delays (though less critical with APIs, it's good practice if rate limits are strict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. API Data Fetching Function (`scrape_remotive_api`)\n",
    "\n",
    "This function is designed to interact with the Remotive API. It constructs the API request with optional parameters for filtering by category, search keywords, and limiting the number of results. The API returns data in JSON format, which is then parsed and converted into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_remotive_api(category=None, search=None, limit=None):\n",
    "    base_api_url = \"https://remotive.com/api/remote-jobs\"\n",
    "    params = {}\n",
    "    if category: \n",
    "        params[\"category\"] = category\n",
    "    if search: \n",
    "        params[\"search\"] = search\n",
    "    if limit: \n",
    "        params[\"limit\"] = limit\n",
    "\n",
    "    job_listings = []\n",
    "    print(f\"Starting to fetch jobs from Remotive API with parameters: {params}\")\n",
    "\n",
    "    try:\n",
    "        response = requests.get(base_api_url, params=params)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "        data = response.json()\n",
    "\n",
    "        if \"jobs\" in data:\n",
    "            for job in data[\"jobs\"]:\n",
    "                job_data = {\n",
    "                    \"Job ID\": job.get(\"id\"),\n",
    "                    \"Job Title\": job.get(\"title\"),\n",
    "                    \"Company Name\": job.get(\"company_name\"),\n",
    "                    \"Publication Date\": job.get(\"publication_date\"),\n",
    "                    \"Job Type\": job.get(\"job_type\"),\n",
    "                    \"Category\": job.get(\"category\"),\n",
    "                    \"Candidate Required Location\": job.get(\"candidate_required_location\"),\n",
    "                    \"Salary Range\": job.get(\"salary\"),\n",
    "                    \"Job Description\": job.get(\"description\"),\n",
    "                    \"Source URL\": job.get(\"url\"),\n",
    "                    \"Company Logo\": job.get(\"company_logo\"),\n",
    "                    \"Job Board\": \"Remotive.com\"\n",
    "                }\n",
    "                job_listings.append(job_data)\n",
    "        else:\n",
    "            print(\"No \'jobs\' key found in the API response.\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error during request to Remotive API: {e}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error decoding JSON response from Remotive API: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "    df = pd.DataFrame(job_listings)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Execution and Data Storage\n",
    "\n",
    "This section demonstrates how to call the `scrape_remotive_api` function, retrieve job data, and save it to a CSV file. For this example, we'll fetch 50 jobs from the 'Software Development' category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example usage: Fetch 50 software development jobs\n",
    "    scraped_data = scrape_remotive_api(category=\"software-dev\", limit=50)\n",
    "    \n",
    "    if not scraped_data.empty:\n",
    "        output_filename = \"remotive_jobs.csv\"\n",
    "        scraped_data.to_csv(output_filename, index=False)\n",
    "        print(f\"Successfully fetched {len(scraped_data)} jobs from Remotive API and saved to {output_filename}\")\n",
    "        display(Markdown(f\"### Sample of Scraped Data ({len(scraped_data)} jobs)\"))\n",
    "        display(scraped_data.head())\n",
    "    else:\n",
    "        print(\"No job listings were fetched from Remotive API. Please check the logs above for errors.\")\n",
    "        display(Markdown(\"### No Data Fetched\"))\n",
    "        display(Markdown(\"The API call did not return any job listings. Review the console output for error messages or check the API documentation for valid parameters.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. API Usage Best Practices and Considerations\n",
    "\n",
    "Using an API for data collection offers several advantages over traditional web scraping:\n",
    "\n",
    "### Reliability\n",
    "\n",
    "APIs provide a stable and structured way to access data. They are less prone to breaking due to website design changes, which is a common challenge with HTML parsing.\n",
    "\n",
    "### Efficiency\n",
    "\n",
    "APIs typically return data in a machine-readable format (like JSON), which is much faster and easier to parse than HTML. This reduces development time and computational resources.\n",
    "\n",
    "### Politeness and Rate Limits\n",
    "\n",
    "API providers usually have clear guidelines on usage and rate limits. Adhering to these limits (e.g., by introducing `time.sleep()` if making multiple sequential calls) ensures continued access and good standing with the service provider. Remotive's API documentation advises a maximum of 4 requests per day for general data, and excessive requests (more than 2x per minute) will be blocked.\n",
    "\n",
    "### Data Quality\n",
    "\n",
    "Data obtained through an API is often cleaner and more consistent, as it's directly provided by the source in a structured format, reducing the need for extensive data cleaning and transformation.\n",
    "\n",
    "### Terms of Service\n",
    "\n",
    "Always review the API's terms of service. For Remotive, it's crucial to link back to the original job URL and mention Remotive as the source if you share their job listings. Also, note that jobs displayed via the public API are delayed by 24 hours.\n",
    "\n",
    "### Integration into BI Projects\n",
    "\n",
    "For a full BI project, the data fetched via this API would be a crucial input. It would then be loaded into a data warehouse, transformed, enriched, and used to build interactive dashboards (e.g., in Power BI) for trend analysis, market insights, and data-driven decision-making regarding remote work trends."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
