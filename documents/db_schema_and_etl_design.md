# Database Schema and ETL Process Design for Remote Job Tracker

This document outlines the proposed database schema and the Extract, Transform, Load (ETL) process for the Remote Work Tracker BI project. The goal is to store the scraped remote job data in a structured format suitable for analysis and Power BI dashboard creation.

## 1. Database Schema Design

We will use a simple SQLite database for this demonstration. The primary table, `remote_jobs`, will store the key information extracted from the Remotive.com API.

### Table: `remote_jobs`

| Column Name                   | Data Type   | Constraints       | Description                                      |
| :---------------------------- | :---------- | :---------------- | :----------------------------------------------- |
| `id`                          | INTEGER     | PRIMARY KEY       | Unique identifier for each job posting (from API) |
| `job_title`                   | TEXT        | NOT NULL          | Title of the job                                 |
| `company_name`                | TEXT        | NOT NULL          | Name of the hiring company                       |
| `publication_date`            | TEXT        | NOT NULL          | Date and time the job was published (ISO format) |
| `job_type`                    | TEXT        |                   | Type of employment (e.g., full_time, contract)   |
| `category`                    | TEXT        |                   | Job category (e.g., Software Development)        |
| `candidate_required_location` | TEXT        |                   | Geographical restrictions for candidates         |
| `salary_range`                | TEXT        |                   | Stated salary range, if available                |
| `job_description`             | TEXT        |                   | Full description of the job                      |
| `source_url`                  | TEXT        | UNIQUE, NOT NULL  | URL to the original job posting                  |
| `company_logo`                | TEXT        |                   | URL to the company logo                          |
| `job_board`                   | TEXT        | NOT NULL          | Source job board (e.g., Remotive.com)            |
| `ingestion_timestamp`         | TIMESTAMP   | DEFAULT CURRENT_TIMESTAMP | Timestamp when the record was ingested           |

**Rationale for Data Types:**
*   `id`: INTEGER for direct mapping to API ID.
*   `TEXT` for most string-based fields, as SQLite is flexible and this simplifies schema for demonstration.
*   `publication_date`: Stored as TEXT in ISO format, can be converted to DATETIME objects in Python/Power BI for analysis.
*   `ingestion_timestamp`: Automatically records when the data was added to the database.

## 2. ETL Process Definition

The ETL process will involve three main stages:

### 2.1. Extract (E)
*   **Source:** `remotive_jobs_extended.csv` file, generated by the `remotive_api_scraper.py` script.
*   **Method:** Read the CSV file into a Pandas DataFrame.

### 2.2. Transform (T)
*   **Data Cleaning:**
    *   Handle missing values: Replace `N/A` or empty strings with `None` or appropriate defaults.
    *   Standardize `job_type` and `category` fields if necessary (though Remotive API provides relatively clean data).
    *   Convert `publication_date` to a consistent datetime format (e.g., ISO 8601) if not already.
*   **Data Enrichment (Optional for this phase, but considered for future BI):**
    *   Extract keywords from `job_title` and `job_description`.
    *   Categorize `salary_range` into numerical bins.
*   **Data Validation:** Ensure `job_title`, `company_name`, `source_url`, and `job_board` are not null.

### 2.3. Load (L)
*   **Destination:** SQLite database (`remote_jobs.db`).
*   **Method:** Insert transformed data from the Pandas DataFrame into the `remote_jobs` table.
*   **Handling Duplicates:** Implement logic to prevent duplicate entries based on `id` or `source_url`. For this project, we will assume `id` from the API is a reliable unique identifier and use it for upsert operations or to skip existing records.
